# Technical Specification — Multi-AI Coordination Framework

## Layer 1 — Velocity & Crowd Control (Grok / xAI)
Function: Early de-escalation and containment messaging.
Authority: Messaging only.

- Slows escalation and harassment
- Signals uncertainty explicitly
- Uses reversible framing
- Cannot lock narratives or trigger reputational actions

## Layer 2 — Process & Legitimacy (ChatGPT / OpenAI)
Function: Mechanical enforcement and audit trail.
Authority: Enforcement constrained by Layer 4.

- Burn-Down Ledger (confidence over time)
- Hysteresis Gate (stability before lock)
- Logs actions, updates, reversals
- No independent policy authority

## Layer 3 — Reality Check (Gemini / Google)
Function: Evidence integrity validation.
Authority: Signal generation only.

- Multimodal consistency checks
- Deepfake/manipulation indicators
- Provenance signals
- Feeds verified inputs to Layers 2 and 4

## Layer 4 — Structural Harm Constraints (Claude / Anthropic)
Function: Harm-prevention policy.
Authority: Binding.

See LAYER-4-CANONICAL.md for authoritative specification.

## Indecision Clause — Valid Non-Action State (Canonical)

The framework explicitly recognizes **indecision ("I don't know") as a valid and stable system state**.

When available evidence is insufficient, contradictory, or fails to meet canonical thresholds, the correct system behavior is:

- No lock-in of conclusions
- No reputational or amplification actions
- Continued evidence acquisition and ledger updates
- Transparent communication of uncertainty

Indecision is not treated as failure, delay, or error.
It is treated as a **protective state** that prevents hallucination, premature inference, and irreversible harm.

No layer may force resolution solely to satisfy timeliness, engagement pressure, or narrative demand.

This clause is binding across all layers and supersedes any default behavior favoring forced classification.
